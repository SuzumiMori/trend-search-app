import streamlit as st
import datetime
from google import genai
from google.genai import types
import os
import json
import pandas as pd
import re
import pydeck as pdk

# ãƒšãƒ¼ã‚¸ã®è¨­å®š
st.set_page_config(page_title="ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆæ¤œç´¢", page_icon="ğŸ—ºï¸")

st.title("ğŸ—ºï¸ ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆMapæ¤œç´¢")
st.markdown("ä¿¡é ¼ã§ãã‚‹æƒ…å ±ã‚½ãƒ¼ã‚¹ï¼ˆFashion Press, PR TIMESç­‰ï¼‰ã«é™å®šã—ã¦æ¤œç´¢ã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®šã‚¨ãƒªã‚¢ ---
with st.sidebar:
    st.header("æ¤œç´¢æ¡ä»¶")
    st.markdown("### ğŸ“ åœ°åŸŸãƒ»å ´æ‰€")
    region = st.text_input("æ¤œç´¢ã—ãŸã„å ´æ‰€", value="æ±äº¬éƒ½æ¸‹è°·åŒº", help="å…·ä½“çš„ãªåœ°åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    st.markdown("---")
    
    st.markdown("### ğŸ“… æœŸé–“æŒ‡å®š")
    today = datetime.date.today()
    next_month = today + datetime.timedelta(days=30)
    
    start_date = st.date_input("é–‹å§‹æ—¥", today)
    end_date = st.date_input("çµ‚äº†æ—¥", next_month)

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ---

if st.button("æ¤œç´¢é–‹å§‹", type="primary"):
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except:
        st.error("âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    if start_date > end_date:
        st.error("âš ï¸ çµ‚äº†æ—¥ã¯é–‹å§‹æ—¥ã‚ˆã‚Šå¾Œã®æ—¥ä»˜ã«ã—ã¦ãã ã•ã„ã€‚")
    else:
        # æ¤œç´¢å‡¦ç†
        client = genai.Client(api_key=api_key)
        status_text = st.empty()
        status_text.info(f"ğŸ” {region}å‘¨è¾ºã®æƒ…å ±ã‚’åé›†ä¸­... (ä¿¡é ¼ã§ãã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢ã®ã¿ã‚’æ¤œç´¢ä¸­)")

        # æ¤œç´¢ç¯„å›²ï¼ˆæœˆå˜ä½ï¼‰
        search_months = f"{start_date.year}å¹´{start_date.month}æœˆ"
        if start_date.month != end_date.month:
            search_months += f"ã€{end_date.year}å¹´{end_date.month}æœˆ"

        # â˜…ã“ã“ãŒãƒã‚¤ãƒ³ãƒˆï¼šæ¤œç´¢å¯¾è±¡ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’æŒ‡å®š
        trusted_sites = "site:fashion-press.net OR site:prtimes.jp OR site:walkerplus.com OR site:timeout.jp OR site:entabe.jp OR site:event-checker.info"

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        prompt = f"""
        ã‚ãªãŸã¯å³æ ¼ãªãƒˆãƒ¬ãƒ³ãƒ‰ãƒªã‚µãƒ¼ãƒãƒ£ãƒ¼ã§ã™ã€‚
        ä»¥ä¸‹ã®ã€Œä¿¡é ¼ã§ãã‚‹ã‚µã‚¤ãƒˆã€ã®ã¿ã‚’å¯¾è±¡ã«Googleæ¤œç´¢ã‚’è¡Œã„ã€æ­£ç¢ºãªã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
        
        ã€æ¤œç´¢ã‚¯ã‚¨ãƒªã®æŒ‡ç¤ºã€‘
        ä»¥ä¸‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã—ã¦ãã ã•ã„ï¼š
        ã€Œ{region} ã‚¤ãƒ™ãƒ³ãƒˆ {search_months} {trusted_sites}ã€
        ã€Œ{region} æ–°è¦ã‚ªãƒ¼ãƒ—ãƒ³ {search_months} {trusted_sites}ã€

        ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šæœŸé–“ã€‘
        {start_date} ã‹ã‚‰ {end_date} ã¾ã§

        ã€å‡ºåŠ›å½¢å¼ï¼ˆJSONã®ã¿ï¼‰ã€‘
        Markdownè£…é£¾ä¸è¦ã€‚ä»¥ä¸‹ã®JSONãƒªã‚¹ãƒˆã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        [
            {{
                "type": "ç¨®åˆ¥(æ–°ãƒ¡ãƒ‹ãƒ¥ãƒ¼/ã‚ªãƒ¼ãƒ—ãƒ³/ã‚¤ãƒ™ãƒ³ãƒˆ)",
                "name": "åº—åã¾ãŸã¯ã‚¤ãƒ™ãƒ³ãƒˆå",
                "place": "å…·ä½“çš„ãªå ´æ‰€",
                "start_date": "YYYY-MM-DD",
                "end_date": "YYYY-MM-DD",
                "description": "æ¦‚è¦",
                "source_name": "ã‚µã‚¤ãƒˆå(ä¾‹: Fashion Press)",
                "url": "è¨˜äº‹ã®URL",
                "lat": ç·¯åº¦(æ•°å€¤),
                "lon": çµŒåº¦(æ•°å€¤)
            }},
            ...
        ]

        ã€çµ¶å¯¾ãƒ«ãƒ¼ãƒ«ã€‘
        1. **æŒ‡å®šã—ãŸä¿¡é ¼ã§ãã‚‹ã‚µã‚¤ãƒˆ(Fashion Press, PR TIMESç­‰)ã®æƒ…å ±ã®ã¿ã‚’æ¡ç”¨ã—ã¦ãã ã•ã„ã€‚** æ€ªã—ã„ãƒ–ãƒ­ã‚°ã‚„ã¾ã¨ã‚ã‚µã‚¤ãƒˆã¯ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚
        2. **URLã¯æ¤œç´¢çµæœã«å‡ºã¦ããŸå®Ÿåœ¨ã™ã‚‹ã‚‚ã®ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„ã€‚** è‡ªåˆ†ã§æ¨æ¸¬ã—ã¦URLã‚’ä½œã‚‰ãªã„ã§ãã ã•ã„ï¼ˆãƒªãƒ³ã‚¯åˆ‡ã‚Œã®åŸå› ã«ãªã‚Šã¾ã™ï¼‰ã€‚
        3. æ˜¨å¹´ã®è¨˜äº‹ï¼ˆ2023å¹´ãªã©ï¼‰ã¯çµ¶å¯¾ã«é™¤å¤–ã—ã¦ãã ã•ã„ã€‚

        ã€æ¡ä»¶ã€‘
        - 5ä»¶ç¨‹åº¦æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
        - ä¸‡ãŒä¸€æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ç„¡ç†ã«æé€ ã›ãšã€è¦‹ã¤ã‹ã£ãŸä»¶æ•°ã ã‘ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        """

        try:
            # AIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            response = client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt,
                config=types.GenerateContentConfig(
                    tools=[types.Tool(google_search=types.GoogleSearch())],
                    response_mime_type="application/json"
                )
            )

            status_text.empty()
            
            # --- JSONãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºãƒ»ä¿®å¾©ãƒ­ã‚¸ãƒƒã‚¯ ---
            text = response.text.replace("```json", "").replace("```", "").strip()
            data = []
            
            try:
                data = json.loads(text)
            except json.JSONDecodeError as e:
                try:
                    if e.msg.startswith("Extra data"):
                        data = json.loads(text[:e.pos])
                    else:
                        match = re.search(r'\[.*\]', text, re.DOTALL)
                        if match:
                            candidate = match.group(0)
                            data = json.loads(candidate)
                except:
                    pass
            
            if not data:
                st.warning("æ¡ä»¶ã«åˆã†æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æœŸé–“ã‚„åœ°åŸŸã‚’å¤‰æ›´ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                st.stop()

            # --- æœŸé–“è¡¨ç¤ºç”¨ã®æ•´å½¢å‡¦ç† ---
            for item in data:
                s_date = item.get('start_date')
                e_date = item.get('end_date')
                if s_date and e_date:
                    if s_date == e_date:
                        item['display_date'] = s_date
                    else:
                        item['display_date'] = f"{s_date} ã€œ {e_date}"
                else:
                    item['display_date'] = s_date or "æ—¥ä»˜ä¸æ˜"

            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å¤‰æ›
            df = pd.DataFrame(data)

            # --- 1. é«˜æ©Ÿèƒ½åœ°å›³ã®è¡¨ç¤º (Voyagerã‚¹ã‚¿ã‚¤ãƒ«) ---
            st.subheader(f"ğŸ“ {region}å‘¨è¾ºã®ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒ—")
            
            if not df.empty and 'lat' in df.columns and 'lon' in df.columns:
                map_df = df.dropna(subset=['lat', 'lon'])
                
                view_state = pdk.ViewState(
                    latitude=map_df['lat'].mean(),
                    longitude=map_df['lon'].mean(),
                    zoom=13,
                    pitch=0,
                )

                layer = pdk.Layer(
                    "ScatterplotLayer",
                    map_df,
                    get_position='[lon, lat]',
                    get_color='[255, 75, 75, 160]',
                    get_radius=200,
                    pickable=True,
                )

                st.pydeck_chart(pdk.Deck(
                    map_style='https://basemaps.cartocdn.com/gl/voyager-gl-style/style.json',
                    initial_view_state=view_state,
                    layers=[layer],
                    tooltip={
                        "html": "<b>{name}</b><br/>{place}<br/><i>{description}</i>",
                        "style": {"backgroundColor": "steelblue", "color": "white"}
                    }
                ))
                st.caption("â€»åœ°å›³ä¸Šã®èµ¤ã„ä¸¸ã«ãƒã‚¦ã‚¹ã‚’ä¹—ã›ã‚‹ã¨è©³ç´°ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
                
                # CSVä½œæˆ
                export_data = []
                for _, row in map_df.iterrows():
                    gaiyou = f"ã€æœŸé–“ã€‘{row.get('display_date')}\n{row.get('description')}"
                    export_data.append({
                        "Name": row.get('name'),
                        "ä½æ‰€": row.get('place'),
                        "æ¦‚è¦": gaiyou,
                        "å…¬å¼ã‚µã‚¤ãƒˆ": row.get('url', '')
                    })
                
                export_df = pd.DataFrame(export_data)
                csv = export_df.to_csv(index=False).encode('utf-8_sig')

                st.download_button(
                    label="ğŸ“¥ Googleãƒã‚¤ãƒãƒƒãƒ—ç”¨CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv,
                    file_name=f"event_map_{region}.csv",
                    mime='text/csv',
                    help="ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Googleãƒã‚¤ãƒãƒƒãƒ—ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã€ã€Œä½æ‰€ã€åˆ—ã‚’ç›®å°ã®å ´æ‰€ã«æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
                )

            else:
                st.warning("åœ°å›³ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

            # --- 2. é€Ÿå ±ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆ ---
            st.markdown("---")
            st.subheader("ğŸ“‹ ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ä¸€è¦§")
            st.caption("â€»ä¿¡é ¼ã§ãã‚‹ãƒ¡ãƒ‡ã‚£ã‚¢ï¼ˆFashion Pressç­‰ï¼‰ã®è¨˜äº‹ã¸ã®ãƒªãƒ³ã‚¯ã§ã™ã€‚")
            
            for item in data:
                url_text = "ãªã—"
                source_label = item.get('source_name', 'è©³ç´°è¨˜äº‹')
                
                if item.get('url'):
                    url_text = f"[ğŸ”— {source_label} ã§è¨˜äº‹ã‚’èª­ã‚€]({item.get('url')})"

                st.markdown(f"""
                - **æœŸé–“**: {item.get('display_date')}
                - **ç¨®åˆ¥**: {item.get('type')}
                - **åº—å/ã‚¤ãƒ™ãƒ³ãƒˆå**: {item.get('name')}
                - **å ´æ‰€**: {item.get('place')}
                - **æ¦‚è¦**: {item.get('description')}
                - **ã‚½ãƒ¼ã‚¹**: {url_text}
                """)

        except Exception as e:
            status_text.empty()
            st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
