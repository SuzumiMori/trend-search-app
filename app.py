import streamlit as st
import datetime
from google import genai
from google.genai import types
import os
import json
import pandas as pd
import re
import pydeck as pdk
import urllib.parse

# ãƒšãƒ¼ã‚¸ã®è¨­å®š
st.set_page_config(page_title="ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆæ¤œç´¢", page_icon="ğŸ—ºï¸")

st.title("ğŸ—ºï¸ ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆMapæ¤œç´¢")
st.markdown("æŒ‡å®šã—ãŸã€Œã‚¤ãƒ™ãƒ³ãƒˆã¾ã¨ã‚ã‚µã‚¤ãƒˆã€ã®ãƒªã‚¹ãƒˆã‹ã‚‰ã€æƒ…å ±ã‚’ä¸€æ‹¬æŠ½å‡ºã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®šã‚¨ãƒªã‚¢ ---
with st.sidebar:
    st.header("æ¤œç´¢æ¡ä»¶")
    st.markdown("### ğŸ“ åœ°åŸŸãƒ»å ´æ‰€")
    region = st.text_input("æ¤œç´¢ã—ãŸã„å ´æ‰€", value="æ±äº¬éƒ½æ¸‹è°·åŒº", help="å…·ä½“çš„ãªåœ°åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    st.markdown("---")
    st.markdown("### ğŸŒ å¯¾è±¡ã‚µã‚¤ãƒˆé¸æŠ")
    
    # æ¤œç´¢å¯¾è±¡ã‚µã‚¤ãƒˆã®å®šç¾©
    SITE_OPTIONS = {
        "Walkerplus (ã‚¤ãƒ™ãƒ³ãƒˆå…¨èˆ¬)": "walkerplus.com",
        "GO TOKYO (å…¬å¼è¦³å…‰æƒ…å ±)": "gotokyo.org",
        "Lets Enjoy Tokyo (ãŠã§ã‹ã‘)": "enjoytokyo.jp",
        "Fashion Press (æ–°åº—ãƒ»ã‚°ãƒƒã‚º)": "fashion-press.net",
        "Event Checker (ã‚¤ãƒ™ãƒ³ãƒˆ)": "event-checker.info",
        "PR TIMES (å…¬å¼ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹)": "prtimes.jp",
        "TimeOut Tokyo (ã‚·ãƒ†ã‚£ã‚¬ã‚¤ãƒ‰)": "timeout.jp"
    }
    
    selected_sites = st.multiselect(
        "æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã‚µã‚¤ãƒˆï¼ˆè¤‡æ•°å¯ï¼‰",
        options=list(SITE_OPTIONS.keys()),
        default=["Walkerplus (ã‚¤ãƒ™ãƒ³ãƒˆå…¨èˆ¬)", "GO TOKYO (å…¬å¼è¦³å…‰æƒ…å ±)", "Lets Enjoy Tokyo (ãŠã§ã‹ã‘)"]
    )
    
    st.info("ğŸ’¡ é¸æŠã—ãŸã‚µã‚¤ãƒˆã®ã€Œã‚¤ãƒ™ãƒ³ãƒˆä¸€è¦§ãƒšãƒ¼ã‚¸ã€ã‚’æ¤œç´¢ã—ã€ãã“ã«ã‚ã‚‹æƒ…å ±ã‚’èª­ã¿å–ã‚Šã¾ã™ã€‚")

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ---

if st.button("æ¤œç´¢é–‹å§‹", type="primary"):
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except:
        st.error("âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    if not selected_sites:
        st.error("âš ï¸ æ¤œç´¢å¯¾è±¡ã‚µã‚¤ãƒˆã‚’å°‘ãªãã¨ã‚‚1ã¤é¸æŠã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # æ¤œç´¢å‡¦ç†
    client = genai.Client(api_key=api_key)
    status_text = st.empty()
    status_text.info(f"ğŸ” {region}ã®æƒ…å ±ã‚’ã€æŒ‡å®šã•ã‚ŒãŸã¾ã¨ã‚ã‚µã‚¤ãƒˆã‹ã‚‰æŠ½å‡ºä¸­... (ç›®æ¨™: 20ä»¶ä»¥ä¸Š)")

    # é¸æŠã•ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ãƒªã‚¹ãƒˆåŒ–
    target_domains = [SITE_OPTIONS[name] for name in selected_sites]
    
    # æ¤œç´¢ã‚¯ã‚¨ãƒªä½œæˆ (site:A OR site:B ...)
    site_query = " OR ".join([f"site:{d}" for d in target_domains])
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompt = f"""
    ã‚ãªãŸã¯ã€ŒWebãƒšãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆæƒ…å ±ã‚’æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒœãƒƒãƒˆã€ã§ã™ã€‚
    ä»¥ä¸‹ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã§Googleæ¤œç´¢ã‚’è¡Œã„ã€æ¤œç´¢çµæœã«å‡ºã¦ãã‚‹**ã‚¤ãƒ™ãƒ³ãƒˆä¸€è¦§ãƒšãƒ¼ã‚¸**ã®å†…å®¹ã‹ã‚‰ã€ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã‚’å¯èƒ½ãªé™ã‚Šå¤šãæŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

    ã€æ¤œç´¢ã‚¯ã‚¨ãƒªã€‘
    ã€Œ{region} ã‚¤ãƒ™ãƒ³ãƒˆä¸€è¦§ é–‹å‚¬ä¸­ {site_query}ã€
    ã€Œ{region} ã‚¤ãƒ™ãƒ³ãƒˆ ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ ä»Šå¾Œ {site_query}ã€
    ã€Œ{region} æ–°åº— ã‚ªãƒ¼ãƒ—ãƒ³æƒ…å ± {site_query}ã€

    ã€æŠ½å‡ºå¯¾è±¡ã€‘
    ç¾åœ¨é–‹å‚¬ä¸­ã€ã¾ãŸã¯ä»Šå¾Œé–‹å‚¬äºˆå®šã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ»æ–°åº—æƒ…å ±ã€‚
    
    ã€å³å®ˆãƒ«ãƒ¼ãƒ«ã€‘
    1. **ä»¶æ•°é‡è¦–**: ãƒªã‚¹ãƒˆã«ã‚ã‚‹æƒ…å ±ã¯ç‰‡ã£ç«¯ã‹ã‚‰æ‹¾ã£ã¦ãã ã•ã„ï¼ˆæœ€å¤§20ã€œ30ä»¶ï¼‰ã€‚
    2. **URLã®æ‰±ã„**: 
       - åŸºæœ¬çš„ã«ã€Œæ¤œç´¢çµæœã®URLï¼ˆã¾ã¨ã‚ãƒšãƒ¼ã‚¸ã®URLï¼‰ã€ã§ã¯ãªãã€**è¨˜äº‹å†…ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€Œå€‹åˆ¥ã®ã‚¤ãƒ™ãƒ³ãƒˆè©³ç´°URLã€**ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚
       - ãªã‘ã‚Œã°ã€Œã¾ã¨ã‚ãƒšãƒ¼ã‚¸ã®URLã€ã§æ§‹ã„ã¾ã›ã‚“ã€‚
       - **æ¶ç©ºã®URLï¼ˆkanko.walkerplus ãªã©ï¼‰ã¯çµ¶å¯¾ã«ä½œæˆç¦æ­¢**ã§ã™ã€‚
    3. **å®Ÿåœ¨æ€§**: ã‚µã‚¤ãƒˆã«è¼‰ã£ã¦ã„ã‚‹ã‚‚ã®ã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

    ã€å‡ºåŠ›å½¢å¼ï¼ˆJSONã®ã¿ï¼‰ã€‘
    [
        {{
            "name": "ã‚¤ãƒ™ãƒ³ãƒˆå",
            "place": "é–‹å‚¬å ´æ‰€",
            "date_info": "æœŸé–“(ä¾‹: é–‹å‚¬ä¸­ã€œ12/25)",
            "description": "æ¦‚è¦(çŸ­ãã¦OK)",
            "source_name": "ã‚µã‚¤ãƒˆå",
            "url": "URL",
            "lat": ç·¯åº¦(æ•°å€¤ãƒ»ä¸æ˜ãªã‚‰null),
            "lon": çµŒåº¦(æ•°å€¤ãƒ»ä¸æ˜ãªã‚‰null)
        }}
    ]
    """

    try:
        # AIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt,
            config=types.GenerateContentConfig(
                tools=[types.Tool(google_search=types.GoogleSearch())],
                response_mime_type="application/json",
                temperature=0.0
            )
        )

        status_text.empty()
        
        # --- JSONãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º ---
        text = response.text.replace("```json", "").replace("```", "").strip()
        data = []
        try:
            data = json.loads(text)
        except json.JSONDecodeError as e:
            try:
                if e.msg.startswith("Extra data"):
                    data = json.loads(text[:e.pos])
                else:
                    match = re.search(r'\[.*\]', text, re.DOTALL)
                    if match:
                        data = json.loads(match.group(0))
            except:
                pass
        
        # --- ç°¡æ˜“URLãƒã‚§ãƒƒã‚¯ ---
        # è¨±å¯ã—ãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã€ã¾ãŸã¯ãã®ã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        cleaned_data = []
        for item in data:
            name = item.get('name', '')
            url = item.get('url', '')
            
            if not name or name.lower() in ['unknown', 'ã‚¤ãƒ™ãƒ³ãƒˆ']:
                continue
            
            # URLã®è£œæ­£ï¼ˆã‚‚ã—httpãŒãªã‘ã‚Œã°Googleæ¤œç´¢ã¸ï¼‰
            if not url or not url.startswith("http") or "kanko.walkerplus" in url:
                search_query = f"{item['name']} {item['place']} ã‚¤ãƒ™ãƒ³ãƒˆ"
                item['url'] = f"https://www.google.com/search?q={urllib.parse.quote(search_query)}"
                item['source_name'] = "Googleæ¤œç´¢"
            
            cleaned_data.append(item)
            
        data = cleaned_data

        if not data:
            st.warning(f"âš ï¸ æŒ‡å®šã•ã‚ŒãŸã‚µã‚¤ãƒˆã‹ã‚‰ã¯æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚µã‚¤ãƒˆã®é¸æŠã‚’å¤‰ãˆã¦ã¿ã¦ãã ã•ã„ã€‚")
            st.stop()

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å¤‰æ›
        df = pd.DataFrame(data)

        # --- 1. é«˜æ©Ÿèƒ½åœ°å›³ (Voyager) ---
        st.subheader(f"ğŸ“ {region}å‘¨è¾ºã®ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒ—")
        st.caption(f"æŠ½å‡ºä»¶æ•°: {len(data)}ä»¶")
        
        # ç·¯åº¦çµŒåº¦ãŒã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã¿åœ°å›³è¡¨ç¤º
        if not df.empty and 'lat' in df.columns and 'lon' in df.columns:
            map_df = df.dropna(subset=['lat', 'lon'])
            
            if not map_df.empty:
                view_state = pdk.ViewState(
                    latitude=map_df['lat'].mean(),
                    longitude=map_df['lon'].mean(),
                    zoom=13,
                    pitch=0,
                )

                layer = pdk.Layer(
                    "ScatterplotLayer",
                    map_df,
                    get_position='[lon, lat]',
                    get_color='[255, 75, 75, 160]',
                    get_radius=200,
                    pickable=True,
                )

                st.pydeck_chart(pdk.Deck(
                    map_style='https://basemaps.cartocdn.com/gl/voyager-gl-style/style.json',
                    initial_view_state=view_state,
                    layers=[layer],
                    tooltip={
                        "html": "<b>{name}</b><br/>{place}<br/><i>{description}</i>",
                        "style": {"backgroundColor": "steelblue", "color": "white"}
                    }
                ))
                st.caption("â€»åœ°å›³ä¸Šã®èµ¤ã„ä¸¸ã«ãƒã‚¦ã‚¹ã‚’ä¹—ã›ã‚‹ã¨è©³ç´°ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
                
                # CSVä½œæˆ
                export_data = []
                for _, row in map_df.iterrows():
                    gaiyou = f"ã€æœŸé–“ã€‘{row.get('date_info')}\n{row.get('description')}"
                    export_data.append({
                        "Name": row.get('name'),
                        "ä½æ‰€": row.get('place'),
                        "æ¦‚è¦": gaiyou,
                        "å…¬å¼ã‚µã‚¤ãƒˆ": row.get('url', '')
                    })
                
                export_df = pd.DataFrame(export_data)
                csv = export_df.to_csv(index=False).encode('utf-8_sig')

                st.download_button(
                    label="ğŸ“¥ Googleãƒã‚¤ãƒãƒƒãƒ—ç”¨CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv,
                    file_name=f"event_map_{region}.csv",
                    mime='text/csv',
                    help="ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Googleãƒã‚¤ãƒãƒƒãƒ—ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã€ã€Œä½æ‰€ã€åˆ—ã‚’ç›®å°ã®å ´æ‰€ã«æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
                )
            else:
                 st.info("â€»ä½ç½®æƒ…å ±ãŒç‰¹å®šã§ããªã‹ã£ãŸãŸã‚ã€åœ°å›³ã«ã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ãŒã€ä»¥ä¸‹ã®ãƒªã‚¹ãƒˆã«ã¯è¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚")
        else:
            st.warning("åœ°å›³ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

        # --- 2. é€Ÿå ±ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆ ---
        st.markdown("---")
        st.subheader("ğŸ“‹ ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ä¸€è¦§")
        
        for item in data:
            url_text = "ãªã—"
            source_label = item.get('source_name', 'æ²è¼‰ã‚µã‚¤ãƒˆ')
            
            # Googleæ¤œç´¢ãƒªãƒ³ã‚¯ã«å·®ã—æ›¿ã‚ã£ãŸå ´åˆã®è¡¨è¨˜
            link_label = f"{source_label} ã§è¦‹ã‚‹"
            if source_label == "Googleæ¤œç´¢":
                link_label = "ğŸ” Googleã§å†æ¤œç´¢"

            if item.get('url'):
                url_text = f"[ğŸ”— {link_label}]({item.get('url')})"

            st.markdown(f"""
            - **æœŸé–“**: {item.get('date_info')}
            - **ã‚¤ãƒ™ãƒ³ãƒˆå**: {item.get('name')}
            - **å ´æ‰€**: {item.get('place')}
            - **æ¦‚è¦**: {item.get('description')}
            - **ã‚½ãƒ¼ã‚¹**: {url_text}
            """)

    except Exception as e:
        status_text.empty()
        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
