import streamlit as st
import datetime
from google import genai
from google.genai import types
import os
import json
import pandas as pd
import re
import pydeck as pdk

# ãƒšãƒ¼ã‚¸ã®è¨­å®š
st.set_page_config(page_title="ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆæ¤œç´¢", page_icon="ğŸ—ºï¸")

st.title("ğŸ—ºï¸ ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆMapæ¤œç´¢")
st.markdown("ä¿¡é ¼ã§ãã‚‹æƒ…å ±ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã€**å¹´å·ãŒä¸€è‡´ã™ã‚‹ç¢ºå®Ÿãªæƒ…å ±ã®ã¿**ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®šã‚¨ãƒªã‚¢ ---
with st.sidebar:
    st.header("æ¤œç´¢æ¡ä»¶")
    st.markdown("### ğŸ“ åœ°åŸŸãƒ»å ´æ‰€")
    region = st.text_input("æ¤œç´¢ã—ãŸã„å ´æ‰€", value="æ±äº¬éƒ½æ¸‹è°·åŒº", help="å…·ä½“çš„ãªåœ°åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    st.info("ğŸ’¡ æ¤œç´¢ç²¾åº¦ã‚’é«˜ã‚ã‚‹ãŸã‚ã€è‡ªå‹•çš„ã«ã€Œä»Šå¹´ã€ã¾ãŸã¯ã€Œæ¥å¹´ã€ã®å¹´å·ã‚’å«ã‚€è¨˜äº‹ã®ã¿ã‚’å³é¸ã—ã¾ã™ã€‚")

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ---

if st.button("æ¤œç´¢é–‹å§‹", type="primary"):
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except:
        st.error("âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    # æ¤œç´¢å‡¦ç†
    client = genai.Client(api_key=api_key)
    status_text = st.empty()
    
    # ä»Šæ—¥ã®æ—¥ä»˜ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¹´
    today = datetime.date.today()
    target_year = today.year
    
    status_text.info(f"ğŸ” {region}ã®æƒ…å ±ã‚’æ¤œç´¢ä¸­... ({target_year}å¹´ã®è¨˜äº‹ã®ã¿ã‚’å³é¸)")

    # ä¿¡é ¼ã§ãã‚‹ã‚µã‚¤ãƒˆãƒ‰ãƒ¡ã‚¤ãƒ³
    trusted_sites = "site:fashion-press.net OR site:prtimes.jp OR site:walkerplus.com OR site:timeout.jp OR site:entabe.jp OR site:event-checker.info"

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompt = f"""
    ã‚ãªãŸã¯ã€ŒWebæ¤œç´¢çµæœã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ­ãƒœãƒƒãƒˆã€ã§ã™ã€‚
    ä»¥ä¸‹ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã§Googleæ¤œç´¢ã‚’è¡Œã„ã€**ã€Œ{target_year}å¹´ã€ã«é–‹å‚¬/ã‚ªãƒ¼ãƒ—ãƒ³**ã•ã‚Œã‚‹æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

    ã€æ¤œç´¢ã‚¯ã‚¨ãƒªã€‘
    ã€Œ{region} ã‚¤ãƒ™ãƒ³ãƒˆ {target_year}å¹´ é–‹å‚¬ä¸­ {trusted_sites}ã€
    ã€Œ{region} ã‚¤ãƒ™ãƒ³ãƒˆ {target_year}å¹´ é–‹å‚¬äºˆå®š {trusted_sites}ã€
    ã€Œ{region} æ–°è¦ã‚ªãƒ¼ãƒ—ãƒ³ {target_year}å¹´ {trusted_sites}ã€

    ã€åŸºæº–æ—¥ã€‘
    æœ¬æ—¥ã¯ {today} ã§ã™ã€‚ã“ã‚Œã‚ˆã‚Šéå»ã«çµ‚äº†ã—ãŸã‚¤ãƒ™ãƒ³ãƒˆã¯é™¤å¤–ã—ã¦ãã ã•ã„ã€‚

    ã€å³å®ˆãƒ«ãƒ¼ãƒ«ï¼šå¹´å·ãƒã‚§ãƒƒã‚¯ã€‘
    1. **è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚„æœ¬æ–‡ã«ã€Œ{target_year}ã€ã¾ãŸã¯ã€Œ{target_year}å¹´ã€ã¨ã„ã†è¡¨è¨˜ãŒæ˜ç¢ºã«ã‚ã‚‹ã‚‚ã®ã ã‘ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚**
    2. å¹´å·ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã€ã¾ãŸã¯å»å¹´ã®å¹´å·ã®è¨˜äº‹ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚
    3. URLã¯æ¤œç´¢çµæœã®ã‚‚ã®ã‚’ãã®ã¾ã¾ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚æé€ ç¦æ­¢ã€‚
    4. è©²å½“æƒ…å ±ãŒãªã„å ´åˆã¯ã€ç©ºã®ãƒªã‚¹ãƒˆ `[]` ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

    ã€å‡ºåŠ›å½¢å¼ï¼ˆJSONã®ã¿ï¼‰ã€‘
    [
        {{
            "type": "ç¨®åˆ¥(æ–°ãƒ¡ãƒ‹ãƒ¥ãƒ¼/ã‚ªãƒ¼ãƒ—ãƒ³/ã‚¤ãƒ™ãƒ³ãƒˆ)",
            "name": "åº—åã¾ãŸã¯ã‚¤ãƒ™ãƒ³ãƒˆå",
            "place": "å…·ä½“çš„ãªå ´æ‰€",
            "start_date": "YYYY-MM-DD",
            "end_date": "YYYY-MM-DD",
            "description": "æ¦‚è¦",
            "source_name": "ã‚µã‚¤ãƒˆå",
            "url": "è¨˜äº‹ã®URL",
            "found_year": "è¨˜äº‹å†…ã§ç¢ºèªã§ããŸå¹´å·(ä¾‹: 2025)",
            "lat": ç·¯åº¦(æ•°å€¤),
            "lon": çµŒåº¦(æ•°å€¤)
        }}
    ]
    """

    try:
        # AIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt,
            config=types.GenerateContentConfig(
                tools=[types.Tool(google_search=types.GoogleSearch())],
                response_mime_type="application/json",
                temperature=0.0
            )
        )

        status_text.empty()
        
        # --- JSONãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º ---
        text = response.text.replace("```json", "").replace("```", "").strip()
        data = []
        
        try:
            data = json.loads(text)
        except json.JSONDecodeError as e:
            try:
                if e.msg.startswith("Extra data"):
                    data = json.loads(text[:e.pos])
                else:
                    match = re.search(r'\[.*\]', text, re.DOTALL)
                    if match:
                        candidate = match.group(0)
                        data = json.loads(candidate)
            except:
                pass
        
        # --- â˜…æœ€å¼·ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç† ---
        # AIãŒæŒã£ã¦ããŸãƒ‡ãƒ¼ã‚¿ã§ã‚‚ã€å¹´å·ãŒé–“é•ã£ã¦ã„ãŸã‚‰ã“ã“ã§æ¨ã¦ã‚‹
        cleaned_data = []
        for item in data:
            # 1. åå‰ãŒãªã„ã‚‚ã®ã¯æ¨ã¦ã‚‹
            name = item.get('name', '').lower()
            if not name or name in ['unknown', 'ã‚¤ãƒ™ãƒ³ãƒˆ', 'æƒ…å ±ãªã—']:
                continue
            
            # 2. URLãŒãªã„ã‚‚ã®ã¯æ¨ã¦ã‚‹
            if not item.get('url'):
                continue

            # 3. ã€é‡è¦ã€‘å¹´å·ãƒã‚§ãƒƒã‚¯
            # AIãŒå ±å‘Šã—ã¦ããŸã€Œfound_yearã€ã‹ã€æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã®ä¸­ã«ã€Œã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¹´ã€ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            is_valid_year = False
            
            # AIãŒå ±å‘Šã—ãŸå¹´å·ã‚’ãƒã‚§ãƒƒã‚¯
            found_year_str = str(item.get('found_year', ''))
            if str(target_year) in found_year_str:
                is_valid_year = True
            
            # é–‹å§‹æ—¥ã®ä¸­ã«å¹´å·ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            elif item.get('start_date') and str(target_year) in str(item.get('start_date')):
                is_valid_year = True

            # 4. éå»ã®æ—¥ä»˜ãƒã‚§ãƒƒã‚¯ (çµ‚äº†æ—¥ãŒæ˜¨æ—¥ã‚ˆã‚Šå‰ã®ã‚‚ã®ã¯æ¨ã¦ã‚‹)
            is_future = True
            if item.get('end_date'):
                try:
                    e_date_obj = datetime.datetime.strptime(item.get('end_date'), "%Y-%m-%d").date()
                    if e_date_obj < today:
                        is_future = False
                except:
                    pass # æ—¥ä»˜å¤‰æ›ã‚¨ãƒ©ãƒ¼ãªã‚‰ã‚¹ãƒ«ãƒ¼

            # åˆæ ¼ã—ãŸã‚‚ã®ã ã‘æ®‹ã™
            if is_valid_year and is_future:
                cleaned_data.append(item)
            
        data = cleaned_data

        # ãƒ‡ãƒ¼ã‚¿ãŒç©ºã ã£ãŸå ´åˆ
        if not data:
            st.warning(f"âš ï¸ {target_year}å¹´ã®æœ€æ–°æƒ…å ±ã¯ã€ç¾åœ¨ä¿¡é ¼ã§ãã‚‹ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info(f"ğŸ’¡ AIã¯ã„ãã¤ã‹ã®å€™è£œã‚’è¦‹ã¤ã‘ã¾ã—ãŸãŒã€{target_year}å¹´ã®ç¢ºè¨¼ãŒå¾—ã‚‰ã‚Œãªã‹ã£ãŸãŸã‚é™¤å¤–ã—ã¾ã—ãŸã€‚")
            st.stop()

        # --- æœŸé–“è¡¨ç¤ºç”¨ã®æ•´å½¢å‡¦ç† ---
        for item in data:
            s_date = item.get('start_date')
            e_date = item.get('end_date')
            
            if not s_date:
                item['display_date'] = "é–‹å‚¬ä¸­/è¿‘æ—¥"
            elif s_date and e_date:
                if s_date == e_date:
                    item['display_date'] = s_date
                else:
                    item['display_date'] = f"{s_date} ã€œ {e_date}"
            else:
                item['display_date'] = s_date

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å¤‰æ›
        df = pd.DataFrame(data)

        # --- 1. é«˜æ©Ÿèƒ½åœ°å›³ (Voyager) ---
        st.subheader(f"ğŸ“ {region}å‘¨è¾ºã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒãƒƒãƒ— ({target_year}å¹´ç‰ˆ)")
        
        if not df.empty and 'lat' in df.columns and 'lon' in df.columns:
            map_df = df.dropna(subset=['lat', 'lon'])
            
            view_state = pdk.ViewState(
                latitude=map_df['lat'].mean(),
                longitude=map_df['lon'].mean(),
                zoom=13,
                pitch=0,
            )

            layer = pdk.Layer(
                "ScatterplotLayer",
                map_df,
                get_position='[lon, lat]',
                get_color='[255, 75, 75, 160]',
                get_radius=200,
                pickable=True,
            )

            st.pydeck_chart(pdk.Deck(
                map_style='https://basemaps.cartocdn.com/gl/voyager-gl-style/style.json',
                initial_view_state=view_state,
                layers=[layer],
                tooltip={
                    "html": "<b>{name}</b><br/>{place}<br/><i>{description}</i>",
                    "style": {"backgroundColor": "steelblue", "color": "white"}
                }
            ))
            st.caption("â€»åœ°å›³ä¸Šã®èµ¤ã„ä¸¸ã«ãƒã‚¦ã‚¹ã‚’ä¹—ã›ã‚‹ã¨è©³ç´°ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
            
            # CSVä½œæˆ
            export_data = []
            for _, row in map_df.iterrows():
                gaiyou = f"ã€æœŸé–“ã€‘{row.get('display_date')}\n{row.get('description')}"
                export_data.append({
                    "Name": row.get('name'),
                    "ä½æ‰€": row.get('place'),
                    "æ¦‚è¦": gaiyou,
                    "å…¬å¼ã‚µã‚¤ãƒˆ": row.get('url', '')
                })
            
            export_df = pd.DataFrame(export_data)
            csv = export_df.to_csv(index=False).encode('utf-8_sig')

            st.download_button(
                label="ğŸ“¥ Googleãƒã‚¤ãƒãƒƒãƒ—ç”¨CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv,
                file_name=f"event_map_{region}.csv",
                mime='text/csv',
                help="ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Googleãƒã‚¤ãƒãƒƒãƒ—ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã€ã€Œä½æ‰€ã€åˆ—ã‚’ç›®å°ã®å ´æ‰€ã«æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            )

        else:
            st.warning("åœ°å›³ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

        # --- 2. é€Ÿå ±ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆ ---
        st.markdown("---")
        st.subheader("ğŸ“‹ æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ä¸€è¦§")
        
        for item in data:
            url_text = "ãªã—"
            source_label = item.get('source_name', 'è©³ç´°è¨˜äº‹')
            
            if item.get('url'):
                url_text = f"[ğŸ”— {source_label} ã§è¨˜äº‹ã‚’èª­ã‚€]({item.get('url')})"

            st.markdown(f"""
            - **æœŸé–“**: {item.get('display_date')}
            - **ç¨®åˆ¥**: {item.get('type')}
            - **åº—å/ã‚¤ãƒ™ãƒ³ãƒˆå**: {item.get('name')}
            - **å ´æ‰€**: {item.get('place')}
            - **æ¦‚è¦**: {item.get('description')}
            - **ã‚½ãƒ¼ã‚¹**: {url_text}
            """)

    except Exception as e:
        status_text.empty()
        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
