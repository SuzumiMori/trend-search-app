import streamlit as st
import datetime
from google import genai
from google.genai import types
import os
import json
import pandas as pd
import re
import pydeck as pdk
import urllib.parse
import time

# ãƒšãƒ¼ã‚¸ã®è¨­å®š
st.set_page_config(page_title="ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆæ¤œç´¢", page_icon="ğŸ—ºï¸")

st.title("ğŸ—ºï¸ ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆMapæ¤œç´¢")
st.markdown("ä¿¡é ¼ã§ãã‚‹æƒ…å ±ã‚µã‚¤ãƒˆã‹ã‚‰ã€ã€ŒæœŸé–“é™å®šã®ã‚¤ãƒ™ãƒ³ãƒˆã€ã‚„ã€Œæ–°åº—æƒ…å ±ã€ã®ã¿ã‚’å³é¸ã—ã¦æŠ½å‡ºã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®šã‚¨ãƒªã‚¢ ---
with st.sidebar:
    st.header("æ¤œç´¢æ¡ä»¶")
    st.markdown("### ğŸ“ åœ°åŸŸãƒ»å ´æ‰€")
    region = st.text_input("æ¤œç´¢ã—ãŸã„å ´æ‰€", value="æ±äº¬éƒ½æ¸‹è°·åŒº", help="å…·ä½“çš„ãªåœ°åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    st.markdown("---")
    st.markdown("### ğŸŒ æ¤œç´¢å¯¾è±¡ã‚µã‚¤ãƒˆ")
    
    SITE_DOMAINS = {
        "Walkerplus": "walkerplus.com",
        "GO TOKYO": "gotokyo.org",
        "Let's Enjoy Tokyo": "enjoytokyo.jp",
        "Fashion Press": "fashion-press.net",
        "TimeOut Tokyo": "timeout.jp",
        "Jorudan": "jorudan.co.jp",
        "PR TIMES": "prtimes.jp"
    }
    
    selected_sites = st.multiselect(
        "æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã‚µã‚¤ãƒˆï¼ˆè¤‡æ•°å¯ï¼‰",
        options=list(SITE_DOMAINS.keys()),
        default=["Walkerplus", "Let's Enjoy Tokyo", "Fashion Press"]
    )
    
    st.info("ğŸ’¡ æ–½è¨­ãã®ã‚‚ã®ã®ç´¹ä»‹ï¼ˆã‚¹ãƒãƒƒãƒˆæƒ…å ±ï¼‰ã¯è‡ªå‹•çš„ã«é™¤å¤–ã—ã¾ã™ã€‚")

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ---

if st.button("æ¤œç´¢é–‹å§‹", type="primary"):
    # äº‹å‰ãƒã‚§ãƒƒã‚¯
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except:
        st.error("âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    if not selected_sites:
        st.error("âš ï¸ æ¤œç´¢å¯¾è±¡ã‚µã‚¤ãƒˆã‚’å°‘ãªãã¨ã‚‚1ã¤é¸æŠã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    try:
        # æ¤œç´¢å‡¦ç†æº–å‚™
        client = genai.Client(api_key=api_key)
        status_text = st.empty()
        status_text.info(f"ğŸ” {region}ã®ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã‚’åé›†ä¸­... (å¸¸è¨­æ–½è¨­ã®é™¤å¤–å‡¦ç†ä¸­)")

        target_domains = [SITE_DOMAINS[name] for name in selected_sites]
        site_query = " OR ".join([f"site:{d}" for d in target_domains])
        
        today = datetime.date.today()
        
        # â˜…ã“ã“ãŒé‡è¦: æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ã€ŒæœŸé–“é™å®šã€å¯„ã‚Šã«ä¿®æ­£
        prompt = f"""
        ã‚ãªãŸã¯ã€Œã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã®é¸åˆ¥ãƒ­ãƒœãƒƒãƒˆã€ã§ã™ã€‚
        ä»¥ä¸‹ã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ä½¿ã„ã€Googleæ¤œç´¢çµæœã‹ã‚‰**æœŸé–“é™å®šã®ã‚¤ãƒ™ãƒ³ãƒˆ**ã‚„**æ–°è¦ã‚ªãƒ¼ãƒ—ãƒ³**ã®æƒ…å ±ã ã‘ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

        ã€æ¤œç´¢ã‚¯ã‚¨ãƒªã€‘
        ã€Œ{region} ã‚¤ãƒ™ãƒ³ãƒˆ æœŸé–“é™å®š {site_query}ã€
        ã€Œ{region} ãƒ•ã‚§ã‚¹ãƒ†ã‚£ãƒãƒ« é–‹å‚¬ {site_query}ã€
        ã€Œ{region} æ–°è¦ã‚ªãƒ¼ãƒ—ãƒ³ {site_query}ã€
        ã€Œ{region} å±•è¦§ä¼š é–‹å‚¬ {site_query}ã€

        ã€åŸºæº–æ—¥ã€‘
        æœ¬æ—¥ã¯ {today} ã§ã™ã€‚çµ‚äº†ã—ãŸã‚¤ãƒ™ãƒ³ãƒˆã¯é™¤å¤–ã—ã¦ãã ã•ã„ã€‚

        ã€å³å®ˆãƒ«ãƒ¼ãƒ«ï¼šæ–½è¨­ç´¹ä»‹ã®æ’é™¤ã€‘
        1. **ãŸã ã®ã€Œæ–½è¨­ç´¹ä»‹ã€ã¯çµ¶å¯¾ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚**
           Ã— æ‚ªã„ä¾‹: ã€Œæ˜æ²»ç¥å®®ã€ã€Œä»£ã€…æœ¨å…¬åœ’ã€ã€Œæ¸‹è°·ãƒ’ã‚«ãƒªã‚¨ã€ (ã“ã‚Œã‚‰ã¯å ´æ‰€ã§ã‚ã‚Šã‚¤ãƒ™ãƒ³ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“)
           â—‹ è‰¯ã„ä¾‹: ã€Œæ˜æ²»ç¥å®® ç§‹ã®å¤§ç¥­ã€ã€Œä»£ã€…æœ¨å…¬åœ’ ã‚ã‚“ã‚ã‚“ã‚«ãƒ¼ãƒ‹ãƒãƒ«ã€ã€Œæ¸‹è°·ãƒ’ã‚«ãƒªã‚¨ ã‚¯ãƒªã‚¹ãƒã‚¹ãƒãƒ¼ã‚±ãƒƒãƒˆã€
        2. **URL**: æ¤œç´¢çµæœã®**è¨˜äº‹URL**ã‚’ãã®ã¾ã¾ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
        3. **ä»¶æ•°**: æœ€å¤§20ä»¶æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

        ã€å‡ºåŠ›å½¢å¼ï¼ˆJSONã®ã¿ï¼‰ã€‘
        [
            {{
                "name": "ã‚¤ãƒ™ãƒ³ãƒˆå(å¿…é ˆ)",
                "place": "é–‹å‚¬å ´æ‰€",
                "date_info": "æœŸé–“(ä¾‹: 11/1ã€œ12/25)",
                "description": "æ¦‚è¦(çŸ­ãã¦OK)",
                "source_name": "ã‚µã‚¤ãƒˆå",
                "url": "è¨˜äº‹ã®URL",
                "lat": ç·¯åº¦(æ•°å€¤ãƒ»ä¸æ˜ãªã‚‰null),
                "lon": çµŒåº¦(æ•°å€¤ãƒ»ä¸æ˜ãªã‚‰null)
            }}
        ]
        """

        # æ¤œç´¢å®Ÿè¡Œé–¢æ•°
        def execute_search(model_name):
            return client.models.generate_content(
                model=model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    tools=[types.Tool(google_search=types.GoogleSearch())],
                    response_mime_type="application/json",
                    temperature=0.0
                )
            )

        response = None
        
        # 1.5-flash-002 ã§å®Ÿè¡Œ
        try:
            response = execute_search("gemini-1.5-flash-002")
        except Exception as e:
            error_msg = str(e)
            if "404" in error_msg or "NOT_FOUND" in error_msg:
                status_text.warning("âš ï¸ ãƒ¢ãƒ‡ãƒ«åˆ‡ã‚Šæ›¿ãˆä¸­...")
                try:
                    time.sleep(2)
                    response = execute_search("gemini-2.0-flash-exp")
                except Exception as e2:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e2}")
                    st.stop()
            else:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.stop()

        status_text.empty()
        
        # --- JSONãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º ---
        text = response.text.replace("```json", "").replace("```", "").strip()
        data = []
        try:
            data = json.loads(text)
        except json.JSONDecodeError as e:
            try:
                if e.msg.startswith("Extra data"):
                    data = json.loads(text[:e.pos])
                else:
                    match = re.search(r'\[.*\]', text, re.DOTALL)
                    if match:
                        data = json.loads(match.group(0))
            except:
                pass
        
        # --- ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° & æ–½è¨­é™¤å¤–ãƒ­ã‚¸ãƒƒã‚¯ ---
        cleaned_data = []
        for item in data:
            name = item.get('name', '')
            place = item.get('place', '')
            url = item.get('url', '')
            
            # 1. åå‰ãŒãªã„ã€unknownç­‰ã¯å‰Šé™¤
            if not name or name.lower() in ['unknown', 'ã‚¤ãƒ™ãƒ³ãƒˆ']:
                continue
            
            # 2. â˜…é‡è¦: ã€Œã‚¤ãƒ™ãƒ³ãƒˆåã€ã¨ã€Œå ´æ‰€åã€ãŒé…·ä¼¼ã—ã¦ã„ã‚‹å ´åˆã¯ã€Œæ–½è¨­ç´¹ä»‹ã€ã¨ã¿ãªã—ã¦å‰Šé™¤
            # ä¾‹: name="ä»£ã€…æœ¨å…¬åœ’", place="ä»£ã€…æœ¨å…¬åœ’" -> å‰Šé™¤
            if name.replace(" ", "") == place.replace(" ", ""):
                continue

            # 3. URLãƒã‚§ãƒƒã‚¯
            is_valid_source = False
            if url and url.startswith("http"):
                for domain in target_domains:
                    if domain in url:
                        is_valid_source = True
                        break
            
            if not is_valid_source:
                search_query = f"{item['name']} {item['place']} ã‚¤ãƒ™ãƒ³ãƒˆ"
                item['url'] = f"https://www.google.com/search?q={urllib.parse.quote(search_query)}"
                item['source_name'] = "Googleæ¤œç´¢"
            
            cleaned_data.append(item)
            
        data = cleaned_data

        if not data:
            st.warning(f"âš ï¸ æœŸé–“é™å®šã®ã‚¤ãƒ™ãƒ³ãƒˆã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.info("ã€Œæ¤œç´¢å¯¾è±¡ã‚µã‚¤ãƒˆã€ã‚’å¤‰æ›´ã™ã‚‹ã‹ã€ã‚¨ãƒªã‚¢ã‚’å¤‰ãˆã¦ã¿ã¦ãã ã•ã„ã€‚")
            st.stop()

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å¤‰æ›
        df = pd.DataFrame(data)

        # --- 1. é«˜æ©Ÿèƒ½åœ°å›³ (Voyager) ---
        st.subheader(f"ğŸ“ {region}å‘¨è¾ºã®ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒ—")
        st.caption(f"æŠ½å‡ºä»¶æ•°: {len(data)}ä»¶")
        
        if not df.empty and 'lat' in df.columns and 'lon' in df.columns:
            map_df = df.dropna(subset=['lat', 'lon'])
            
            if not map_df.empty:
                view_state = pdk.ViewState(
                    latitude=map_df['lat'].mean(),
                    longitude=map_df['lon'].mean(),
                    zoom=13,
                    pitch=0,
                )

                layer = pdk.Layer(
                    "ScatterplotLayer",
                    map_df,
                    get_position='[lon, lat]',
                    get_color='[255, 75, 75, 160]',
                    get_radius=200,
                    pickable=True,
                )

                st.pydeck_chart(pdk.Deck(
                    map_style='https://basemaps.cartocdn.com/gl/voyager-gl-style/style.json',
                    initial_view_state=view_state,
                    layers=[layer],
                    tooltip={
                        "html": "<b>{name}</b><br/>{place}<br/><i>{description}</i>",
                        "style": {"backgroundColor": "steelblue", "color": "white"}
                    }
                ))
                st.caption("â€»åœ°å›³ä¸Šã®èµ¤ã„ä¸¸ã«ãƒã‚¦ã‚¹ã‚’ä¹—ã›ã‚‹ã¨è©³ç´°ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
                
                # CSVä½œæˆ
                export_data = []
                for _, row in map_df.iterrows():
                    gaiyou = f"ã€æœŸé–“ã€‘{row.get('date_info')}\n{row.get('description')}"
                    export_data.append({
                        "Name": row.get('name'),
                        "ä½æ‰€": row.get('place'),
                        "æ¦‚è¦": gaiyou,
                        "å…¬å¼ã‚µã‚¤ãƒˆ": row.get('url', '')
                    })
                
                export_df = pd.DataFrame(export_data)
                csv = export_df.to_csv(index=False).encode('utf-8_sig')

                st.download_button(
                    label="ğŸ“¥ Googleãƒã‚¤ãƒãƒƒãƒ—ç”¨CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv,
                    file_name=f"event_map_{region}.csv",
                    mime='text/csv',
                    help="ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Googleãƒã‚¤ãƒãƒƒãƒ—ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã€ã€Œä½æ‰€ã€åˆ—ã‚’ç›®å°ã®å ´æ‰€ã«æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
                )
            else:
                 st.info("â€»ä½ç½®æƒ…å ±ãŒç‰¹å®šã§ããªã‹ã£ãŸãŸã‚ã€åœ°å›³ã«ã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ãŒã€ä»¥ä¸‹ã®ãƒªã‚¹ãƒˆã«ã¯è¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚")
        else:
            st.warning("åœ°å›³ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

        # --- 2. é€Ÿå ±ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆ ---
        st.markdown("---")
        st.subheader("ğŸ“‹ ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ä¸€è¦§")
        
        for item in data:
            url_text = "ãªã—"
            source_label = item.get('source_name', 'æ²è¼‰ã‚µã‚¤ãƒˆ')
            
            link_label = f"{source_label} ã§è¦‹ã‚‹"
            if source_label == "Googleæ¤œç´¢":
                link_label = "ğŸ” Googleã§å†æ¤œç´¢"

            if item.get('url'):
                url_text = f"[ğŸ”— {link_label}]({item.get('url')})"

            st.markdown(f"""
            - **æœŸé–“**: {item.get('date_info')}
            - **ã‚¤ãƒ™ãƒ³ãƒˆå**: {item.get('name')}
            - **å ´æ‰€**: {item.get('place')}
            - **æ¦‚è¦**: {item.get('description')}
            - **ã‚½ãƒ¼ã‚¹**: {url_text}
            """)

    except Exception as e:
        status_text.empty()
        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
