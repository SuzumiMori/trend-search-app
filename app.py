import streamlit as st
import datetime
from google import genai
from google.genai import types
import os
import json
import pandas as pd
import pydeck as pdk
import requests
from bs4 import BeautifulSoup
import time
import urllib.parse

# ãƒšãƒ¼ã‚¸ã®è¨­å®š
st.set_page_config(page_title="ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆæ¤œç´¢", page_icon="ğŸ“–", layout="wide") # æ¨ªå¹…ã‚’åºƒãä½¿ã†è¨­å®š

st.title("ğŸ“– ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã€Œä¸€æ‹¬ç›´èª­ã€æŠ½å‡ºã‚¢ãƒ—ãƒª")
st.markdown("æŒ‡å®šã—ãŸWebãƒšãƒ¼ã‚¸ã‚’AIãŒèª­ã¿è¾¼ã¿ã€æƒ…å ±ã‚’çµ±åˆãƒ»æ•´ç†ã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®šã‚¨ãƒªã‚¢ ---
with st.sidebar:
    st.header("èª­ã¿è¾¼ã¿å¯¾è±¡ (è¤‡æ•°é¸æŠå¯)")
    
    # ãƒ—ãƒªã‚»ãƒƒãƒˆURLãƒªã‚¹ãƒˆ
    PRESET_URLS = {
        "Walkerplus (ä»Šæ—¥ã®ã‚¤ãƒ™ãƒ³ãƒˆ/æ±äº¬)": "https://www.walkerplus.com/event_list/today/ar0300/",
        "Walkerplus (ä»Šé€±æœ«ã®ã‚¤ãƒ™ãƒ³ãƒˆ/æ±äº¬)": "https://www.walkerplus.com/event_list/weekend/ar0300/",
        "Walkerplus (æ¥é€±ã®ã‚¤ãƒ™ãƒ³ãƒˆ/æ±äº¬)": "https://www.walkerplus.com/event_list/next_week/ar0300/",
        "Let's Enjoy Tokyo (ç¾åœ¨é–‹å‚¬ä¸­/æ¸‹è°·)": "https://www.enjoytokyo.jp/event/list/area1302/?date_type=current",
        "Let's Enjoy Tokyo (ä»Šé€±æœ«/æ¸‹è°·)": "https://www.enjoytokyo.jp/event/list/area1302/?date_type=weekend",
        "Fashion Press (æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹)": "https://www.fashion-press.net/news/",
        "TimeOut Tokyo (æ±äº¬ã®ã‚¤ãƒ™ãƒ³ãƒˆ)": "https://www.timeout.jp/tokyo/ja/things-to-do"
    }
    
    selected_presets = st.multiselect(
        "ãƒ—ãƒªã‚»ãƒƒãƒˆã‹ã‚‰é¸æŠ",
        options=list(PRESET_URLS.keys()),
        default=["Walkerplus (ä»Šæ—¥ã®ã‚¤ãƒ™ãƒ³ãƒˆ/æ±äº¬)", "Let's Enjoy Tokyo (ç¾åœ¨é–‹å‚¬ä¸­/æ¸‹è°·)"]
    )
    
    st.markdown("---")
    st.markdown("### ğŸ”— ã‚«ã‚¹ã‚¿ãƒ URL")
    custom_urls_text = st.text_area(
        "ãã®ä»–ã®URLï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šã§è¤‡æ•°å…¥åŠ›å¯ï¼‰",
        placeholder="https://...\nhttps://...",
        height=100
    )

    st.info("ğŸ’¡ é‡è¤‡ã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã¯è‡ªå‹•çš„ã«çµ±åˆã•ã‚Œã¾ã™ã€‚")

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ---

if st.button("ä¸€æ‹¬èª­ã¿è¾¼ã¿é–‹å§‹", type="primary"):
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except:
        st.error("âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒªã‚¹ãƒˆä½œæˆ
    targets = []
    for label in selected_presets:
        targets.append({"url": PRESET_URLS[label], "label": label})
    
    if custom_urls_text:
        for url in custom_urls_text.split('\n'):
            url = url.strip()
            if url and url.startswith("http"):
                domain = urllib.parse.urlparse(url).netloc
                targets.append({"url": url, "label": f"ã‚«ã‚¹ã‚¿ãƒ  ({domain})"})
    
    # é‡è¤‡URLé™¤å»
    unique_targets = {t['url']: t for t in targets}
    targets = list(unique_targets.values())

    if not targets:
        st.error("âš ï¸ URLãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    # å‡¦ç†é–‹å§‹
    all_data = []
    client = genai.Client(api_key=api_key)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    total_urls = len(targets)
    
    # --- ãƒ«ãƒ¼ãƒ—å‡¦ç† ---
    for i, target in enumerate(targets):
        url = target['url']
        label = target['label']
        
        progress_bar.progress(i / total_urls)
        status_text.info(f"â³ ({i+1}/{total_urls}) èª­ã¿è¾¼ã¿ä¸­...: {label}")
        
        try:
            # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
            headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"}
            response = requests.get(url, headers=headers, timeout=15)
            response.encoding = response.apparent_encoding
            
            if response.status_code != 200:
                st.warning(f"âš ï¸ ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {url}")
                continue

            soup = BeautifulSoup(response.text, "html.parser")
            for script in soup(["script", "style", "nav", "footer", "iframe", "header"]):
                script.decompose()
            page_text = soup.get_text(separator="\n", strip=True)[:40000]

            # AIè§£æ
            prompt = f"""
            ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
            ä»¥ä¸‹ã®Webãƒšãƒ¼ã‚¸ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€Œã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ã€ã‚’æŠ½å‡ºã—ã€JSONå½¢å¼ã§ãƒªã‚¹ãƒˆåŒ–ã—ã¦ãã ã•ã„ã€‚

            ã€ãƒšãƒ¼ã‚¸æƒ…å ±ã€‘
            URL: {url}
            ã‚µã‚¤ãƒˆå: {label}
            ã€ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã€‘
            {page_text}

            ã€æŠ½å‡ºãƒ«ãƒ¼ãƒ«ã€‘
            1. ã‚¤ãƒ™ãƒ³ãƒˆåã€æœŸé–“ã€å ´æ‰€ã€æ¦‚è¦ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
            2. ãƒ†ã‚­ã‚¹ãƒˆã«ãªã„æƒ…å ±ã¯å‰µä½œã›ãšã€ä¸æ˜ãªã‚‰ç©ºæ¬„ã«ã—ã¦ãã ã•ã„ã€‚
            3. `lat` `lon` ã¯å ´æ‰€åã‹ã‚‰æ¨æ¸¬ã—ã¦åŸ‹ã‚ã¦ãã ã•ã„ã€‚
            4. `source_url` ã¯ã“ã®ãƒšãƒ¼ã‚¸ã®URL({url})ã¨ã—ã¦ãã ã•ã„ã€‚

            ã€å‡ºåŠ›å½¢å¼ï¼ˆJSONã®ã¿ï¼‰ã€‘
            [
                {{
                    "name": "ã‚¤ãƒ™ãƒ³ãƒˆå",
                    "place": "é–‹å‚¬å ´æ‰€",
                    "date_info": "æœŸé–“",
                    "description": "æ¦‚è¦(ç°¡æ½”ã«)",
                    "lat": ç·¯åº¦(æ•°å€¤),
                    "lon": çµŒåº¦(æ•°å€¤)
                }}
            ]
            """

            ai_response = client.models.generate_content(
                model="gemini-2.0-flash-exp",
                contents=prompt,
                config=types.GenerateContentConfig(response_mime_type="application/json", temperature=0.0)
            )
            
            extracted_list = json.loads(ai_response.text.replace("```json", "").replace("```", "").strip())
            
            if isinstance(extracted_list, list):
                for item in extracted_list:
                    item['source_label'] = label
                    item['source_url'] = url
                    all_data.append(item)
            
            time.sleep(1)

        except Exception as e:
            st.warning(f"ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ: {label} (ã‚¨ãƒ©ãƒ¼: {e})")
            continue

    progress_bar.progress(100)
    time.sleep(0.5)
    progress_bar.empty()

    if not all_data:
        st.error("æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()

    # --- é‡è¤‡å‰Šé™¤ãƒ­ã‚¸ãƒƒã‚¯ ---
    # ã‚¤ãƒ™ãƒ³ãƒˆåã¨å ´æ‰€ã‚’æ­£è¦åŒ–ã—ã¦ã‚­ãƒ¼ã«ã—ã€æ—¢ã«ã‚ã£ãŸã‚‰è¿½åŠ ã—ãªã„
    unique_data = []
    seen_keys = set()

    for item in all_data:
        # ç©ºç™½å‰Šé™¤ãƒ»å°æ–‡å­—åŒ–ã—ã¦æ¯”è¼ƒç”¨ã‚­ãƒ¼ã‚’ä½œæˆ
        name_key = str(item.get('name', '')).replace(" ", "").replace("ã€€", "").lower()
        place_key = str(item.get('place', '')).replace(" ", "").replace("ã€€", "").lower()
        
        # ã‚­ãƒ¼ãŒç©ºãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
        if not name_key:
            continue

        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚­ãƒ¼: (ã‚¤ãƒ™ãƒ³ãƒˆå, å ´æ‰€å)
        # â€»å ´æ‰€ãŒå¤‰ã‚ã‚Œã°åŒåã‚¤ãƒ™ãƒ³ãƒˆã§ã‚‚åˆ¥ç‰©ã¨ã¿ãªã™
        unique_key = (name_key, place_key)

        if unique_key not in seen_keys:
            seen_keys.add(unique_key)
            unique_data.append(item)
    
    status_text.success(f"ğŸ‰ å®Œäº†ï¼ {len(all_data)}ä»¶ä¸­ {len(all_data) - len(unique_data)}ä»¶ã®é‡è¤‡ã‚’å‰Šé™¤ã—ã€{len(unique_data)}ä»¶ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    df = pd.DataFrame(unique_data)

    # --- 1. ãƒãƒƒãƒ—è¡¨ç¤º ---
    st.subheader("ğŸ“ ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒƒãƒ—")
    if not df.empty and 'lat' in df.columns and 'lon' in df.columns:
        map_df = df.dropna(subset=['lat', 'lon'])
        if not map_df.empty:
            view_state = pdk.ViewState(
                latitude=map_df['lat'].mean(),
                longitude=map_df['lon'].mean(),
                zoom=11,
                pitch=0,
            )
            layer = pdk.Layer(
                "ScatterplotLayer",
                map_df,
                get_position='[lon, lat]',
                get_color='[255, 75, 75, 160]',
                get_radius=300,
                pickable=True,
            )
            st.pydeck_chart(pdk.Deck(
                map_style='https://basemaps.cartocdn.com/gl/voyager-gl-style/style.json',
                initial_view_state=view_state,
                layers=[layer],
                tooltip={"html": "<b>{name}</b><br/>{place}<br/><i>{date_info}</i>"}
            ))

    # --- 2. ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º (ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆé¢¨) ---
    st.markdown("---")
    st.subheader("ğŸ“‹ ã‚¤ãƒ™ãƒ³ãƒˆä¸€è¦§ (ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼)")

    # è¡¨ç¤ºç”¨ã«ã‚«ãƒ©ãƒ ã‚’æ•´ç†
    display_cols = ['date_info', 'name', 'place', 'description', 'source_label', 'source_url']
    display_df = df[display_cols].copy()
    
    # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›´
    display_df.columns = ['æœŸé–“', 'ã‚¤ãƒ™ãƒ³ãƒˆå', 'å ´æ‰€', 'æ¦‚è¦', 'æƒ…å ±æº', 'ãƒªãƒ³ã‚¯URL']

    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º
    st.dataframe(
        display_df,
        use_container_width=True, # æ¨ªå¹…ã„ã£ã±ã„ã«åºƒã’ã‚‹
        column_config={
            "ãƒªãƒ³ã‚¯URL": st.column_config.LinkColumn(
                "å…ƒè¨˜äº‹ã¸", # è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆ
                display_text="ğŸ”— ãƒªãƒ³ã‚¯ã‚’é–‹ã" # ã‚»ãƒ«å†…ã®è¡¨ç¤º
            ),
            "æ¦‚è¦": st.column_config.TextColumn(
                "æ¦‚è¦",
                width="large" # æ¦‚è¦æ¬„ã‚’åºƒã‚ã«
            )
        },
        hide_index=True # è¡Œç•ªå·ã‚’éš ã™
    )

    # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    csv = display_df.to_csv(index=False).encode('utf-8_sig')
    st.download_button(
        label="ğŸ“¥ CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv,
        file_name="events_list.csv",
        mime='text/csv'
    )
